# -*- coding: utf-8 -*-
"""finetune_ppo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xgXfPB7WzXMjIOHUnHfRpkeXbVZ9Vu4v
"""

!pip install torch_geometric transformers accelerate

!pip install joblib selfies rdkit

# finetune_ppo.py
"""
Final PPO Fine-tuning Pipeline using the HYBRID GNN+XGBoost Reward Model.
"""
import os
import torch
import torch.nn.functional as F
import torch.optim as optim
import numpy as np
import pandas as pd
import pickle
import joblib
import selfies as sf
from tqdm import tqdm
from rdkit import Chem
from rdkit.Chem import QED
from rdkit.Chem.rdMolDescriptors import GetMorganFingerprintAsBitVect  # Updated import
import matplotlib.pyplot as plt
from typing import Dict, List
import copy

# --- Modular Imports ---
from models import SelfiesGenerator, ValueNetwork, GNNEmbedder # Note: GNNEmbedder
from utils_featurizers import MoleculeProcessor

# --- Import Required Libraries ---
try:
    from torch_geometric.data import Batch
except ImportError as e:
    print(f"Missing critical library: {e}\nPlease run: pip install torch_geometric")
    exit()

# --- Global Setup ---
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f" Project setup: Using device -> {DEVICE}")

# =============================================================================
# SECTION 1: THE NEW HYBRID REWARD FUNCTION
# =============================================================================

class HybridRewardFunction:
    """Calculates reward using the GNN Embedder + XGBoost hybrid model."""
    def __init__(self, gnn_embedder, xgboost_model, mol_processor):
        self.gnn_embedder = gnn_embedder.to(DEVICE).eval()
        self.xgb_model = xgboost_model
        self.mol_processor = mol_processor
        # Morgan Fingerprint settings
        self.fp_radius = 2
        self.fp_bits = 2048

    @torch.no_grad()
    def calculate_rewards_batch(self, smiles_list: List[str]) -> np.ndarray:
        rewards = np.zeros(len(smiles_list))
        valid_graphs, valid_indices, valid_smiles = [], [], []

        for i, smiles in enumerate(smiles_list):
            mol = Chem.MolFromSmiles(smiles)
            if mol:
                graph = self.mol_processor.smiles_to_graph(smiles)
                if graph:
                    valid_graphs.append(graph)
                    valid_indices.append(i)
                    valid_smiles.append(smiles)

        if not valid_graphs:
            return rewards

        # 1. Get GNN embeddings in a batch
        batch = Batch.from_data_list(valid_graphs).to(DEVICE)
        gnn_embeddings = self.gnn_embedder(batch).cpu().numpy()

        # 2. Get Morgan Fingerprints (using updated API)
        fingerprints = []
        for smiles in valid_smiles:
            mol = Chem.MolFromSmiles(smiles)
            # Use the new MorganGenerator API to avoid deprecation warning
            try:
                from rdkit.Chem.rdMolDescriptors import GetMorganGenerator
                mg = GetMorganGenerator(radius=self.fp_radius, fpSize=self.fp_bits)
                fp = mg.GetFingerprintAsNumPy(mol)
            except ImportError:
                # Fallback to old method if new one isn't available
                fp = GetMorganFingerprintAsBitVect(mol, radius=self.fp_radius, nBits=self.fp_bits)
                fp = np.array(fp)
            fingerprints.append(fp)
        fingerprints = np.array(fingerprints)

        # 3. Combine features and predict with XGBoost
        combined_features = np.concatenate([fingerprints, gnn_embeddings], axis=1)
        # Use predict_proba to get probability of the positive class (class 1)
        activity_scores = self.xgb_model.predict_proba(combined_features)[:, 1]

        # 4. Calculate final reward (GNN+XGB score + QED)
        for i, score, smiles in zip(valid_indices, activity_scores, valid_smiles):
            qed_score = QED.qed(Chem.MolFromSmiles(smiles))
            rewards[i] = 0.8 * score + 0.2 * qed_score # Weighted reward

        return rewards

# =============================================================================
# SECTION 2: THE PPO TRAINER
# =============================================================================

class PPOTrainer:
    """the PPO fine-tuning process."""
    def __init__(self, policy_model, value_model, reward_function, vocab):
        self.policy = policy_model.to(DEVICE)
        self.reference = copy.deepcopy(policy_model).to(DEVICE).eval()
        for param in self.reference.parameters():
            param.requires_grad = False

        self.value = value_model.to(DEVICE)
        self.reward_fn = reward_function

        self.token_to_idx, self.idx_to_token = vocab['token_to_idx'], vocab['idx_to_token']
        self.sos, self.eos, self.pad = [self.token_to_idx.get(k) for k in ['<SOS>', '<EOS>', '<PAD>']]

        self.config = {'lr_policy': 1e-5, 'lr_value': 1e-4, 'clip_epsilon': 0.2,
                       'ppo_epochs': 4, 'kl_coef': 0.05}  # Increased KL coefficient

        self.policy_optimizer = optim.Adam(self.policy.parameters(), lr=self.config['lr_policy'])
        self.value_optimizer = optim.Adam(self.value.parameters(), lr=self.config['lr_value'])

    def train_step(self, batch_size: int, max_length: int):
        sequences, policy_log_probs = self._generate_rollout(batch_size, max_length)
        smiles_list = self._decode(sequences)
        raw_rewards = self.reward_fn.calculate_rewards_batch(smiles_list)

        with torch.no_grad():
            ref_log_probs = self.reference.get_log_probs(sequences[:, :-1], sequences[:, 1:])
        kl_div = (policy_log_probs - ref_log_probs).cpu().numpy()
        final_rewards = raw_rewards - self.config['kl_coef'] * kl_div

        advantages, returns = self._calculate_advantages(sequences, final_rewards)
        self._ppo_update(sequences, policy_log_probs, advantages, returns)
        return np.mean(raw_rewards), np.mean(kl_div)

    @torch.no_grad()
    def _generate_rollout(self, batch_size, max_length):
        self.policy.eval()
        sequences = torch.full((batch_size, 1), self.sos, dtype=torch.long, device=DEVICE)
        policy_log_probs = torch.zeros(batch_size, device=DEVICE, dtype=torch.float32)  # explicit float32
        is_finished = torch.zeros(batch_size, dtype=torch.bool, device=DEVICE)
        for _ in range(max_length - 1):
            if is_finished.all():
                break
            logits, _ = self.policy(sequences)
            probs = F.softmax(logits[:, -1, :], dim=-1)
            next_tokens = torch.multinomial(probs, 1)
            log_p = probs.gather(1, next_tokens).squeeze(-1)
            policy_log_probs += torch.log(log_p + 1e-10) * (~is_finished).float()  # convert to float
            sequences = torch.cat([sequences, next_tokens], dim=1)
            is_finished |= (next_tokens.squeeze(-1) == self.eos)
        return sequences, policy_log_probs

    def _calculate_advantages(self, sequences, rewards):
        with torch.no_grad():
            values = self.value(sequences).cpu().numpy()
        advantages = rewards - values
        advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)
        # FIXED: explicit float32 conversion
        return torch.tensor(advantages, device=DEVICE, dtype=torch.float32), torch.tensor(rewards, device=DEVICE, dtype=torch.float32)

    def _ppo_update(self, sequences, old_log_probs, advantages, returns):
        self.policy.train()
        for _ in range(self.config['ppo_epochs']):
            current_log_probs = self.policy.get_log_probs(sequences[:, :-1], sequences[:, 1:])
            ratio = torch.exp(current_log_probs - old_log_probs.detach())
            surr1 = ratio * advantages
            surr2 = torch.clamp(ratio, 1 - self.config['clip_epsilon'], 1 + self.config['clip_epsilon']) * advantages
            self.policy_optimizer.zero_grad()
            (-torch.min(surr1, surr2)).mean().backward()
            torch.nn.utils.clip_grad_norm_(self.policy.parameters(), 1.0)  # Added gradient clipping
            self.policy_optimizer.step()

            self.value_optimizer.zero_grad()
            F.mse_loss(self.value(sequences), returns).backward()
            torch.nn.utils.clip_grad_norm_(self.value.parameters(), 1.0)  # Added gradient clipping
            self.value_optimizer.step()

    def _decode(self, sequences: torch.Tensor) -> List[str]:
        smiles_list = []
        for seq in sequences.cpu().tolist():
            try:
                tokens = [self.idx_to_token[i] for i in seq[1:] if i not in [self.sos, self.pad]]
                selfies_str = "".join(tokens).split('<EOS>')[0]
                smiles_list.append(sf.decoder(selfies_str))
            except Exception:
                smiles_list.append("")
        return smiles_list

# =============================================================================
# SECTION 3: MAIN EXECUTION PIPELINE
# =============================================================================

def main():
    print("\n--- DprE1 Molecule Generation via PPO (Hybrid Reward) ---")

    # 1. Load all components
    print("--- Loading all project components ---")
    # Note: We don't need the descriptor_scaler for the hybrid model's featurizer
    mol_processor = MoleculeProcessor(descriptor_scaler=None)
    with open('vocabulary_selfies.pkl', 'rb') as f:
        vocab = pickle.load(f)

    # Load the HYBRID model components
    xgboost_model = joblib.load('xgboost_hybrid_model.pkl')
    gnn_embedder_ckpt = torch.load('gnn_embedder_model.pth', map_location=DEVICE)
    gnn_embedder = GNNEmbedder(atom_dim=2) # From utils file
    gnn_embedder.load_state_dict(gnn_embedder_ckpt)

    # Load the generative model components
    gen_ckpt = torch.load('pretrained_selfies_agent.pt', map_location=DEVICE, weights_only=False)
    arch = {'vocab_size': 141, 'embed_size': 128, 'hidden_size': 512, 'num_layers': 2}
    print(f"üß¨ Generator architecture: V={arch['vocab_size']}, E={arch['embed_size']}, H={arch['hidden_size']}, L={arch['num_layers']}")

    policy = SelfiesGenerator(**arch)
    policy.load_state_dict(gen_ckpt)
    value = ValueNetwork(**arch)

    print("‚úÖ All components loaded successfully.")

    # 2. Initialize the trainer with the NEW reward function
    reward_function = HybridRewardFunction(gnn_embedder, xgboost_model, mol_processor)
    trainer = PPOTrainer(policy, value, reward_function, vocab)

    # 3. The Training Loop
    print("\n--- Starting PPO Fine-Tuning ---")
    NUM_ITERATIONS, BATCH_SIZE = 200, 64
    all_rewards, top_molecules = [], {}

    pbar = tqdm(range(NUM_ITERATIONS), desc="PPO Iteration")
    for i in pbar:
        try:
            avg_reward, avg_kl = trainer.train_step(batch_size=BATCH_SIZE, max_length=100)
            all_rewards.append(avg_reward)
            pbar.set_postfix({"Reward": f"{avg_reward:.3f}", "KL Div": f"{avg_kl:.2f}"})

            if i > 0 and i % 10 == 0:
                sequences, _ = trainer._generate_rollout(20, 100)
                smiles = trainer._decode(sequences)
                rewards = trainer.reward_fn.calculate_rewards_batch(smiles)
                valid_smiles = [s for s in smiles if s]  # Count valid SMILES
                max_reward = max(rewards) if len(rewards) > 0 else 0
                print(f"Iter {i}: {len(valid_smiles)}/20 valid SMILES, max reward: {max_reward:.3f}")

                # Lower threshold - save top molecules above 75th percentile of current rewards
                threshold = max(0.18, np.percentile(rewards[rewards > 0], 75)) if len(rewards[rewards > 0]) > 0 else 0.18
                for s, r in zip(smiles, rewards):
                    if s and r > threshold:
                        top_molecules[s] = r
        except Exception as e:
            print(f"Error in iteration {i}: {e}")
            continue

    # 4. Save Results
    print("\n‚úÖ Fine-tuning complete!")
    torch.save(trainer.policy.state_dict(), 'finetuned_ppo_agent.pt')

    if top_molecules:
        df = pd.DataFrame(sorted(top_molecules.items(), key=lambda i: i[1], reverse=True),
                     columns=["SMILES", "Score"])
        df.to_csv("ppo_generated_molecules_hybrid.csv", index=False)
        print(f"üíæ Saved {len(df)} top molecules to ppo_generated_molecules_hybrid.csv")
        print(f"Score range: {df['Score'].min():.3f} - {df['Score'].max():.3f}")
    else:
        print("‚ö†Ô∏è  No high-scoring molecules found. Consider lowering the threshold.")

    plt.figure(figsize=(10, 5))
    pd.Series(all_rewards).rolling(10).mean().plot()
    plt.title("Average Reward per PPO Iteration (10-step rolling average)")
    plt.xlabel("Iteration"), plt.ylabel("Average Reward"), plt.grid(True)
    plt.savefig("ppo_reward_curve_hybrid.png"), plt.show()

if __name__ == '__main__':
    main()

# analyze_generated_molecules.py
"""
Analyze the PPO-generated molecules for drug-likeness and novelty.
"""
import pandas as pd
import numpy as np
from rdkit import Chem
from rdkit.Chem import Descriptors, QED, Crippen
from rdkit.Chem import rdMolDescriptors
import matplotlib.pyplot as plt
import seaborn as sns

def analyze_molecules(csv_path="ppo_generated_molecules_hybrid.csv"):
    """Comprehensive analysis of generated molecules."""

    # Load the generated molecules
    df = pd.read_csv(csv_path)
    print(f" Analyzing {len(df)} generated molecules...")
    print(f" Score range: {df['Score'].min():.3f} - {df['Score'].max():.3f}")

    # Calculate molecular properties
    properties = []
    valid_mols = 0

    for idx, row in df.iterrows():
        smiles = row['SMILES']
        mol = Chem.MolFromSmiles(smiles)

        if mol is None:
            continue

        valid_mols += 1

        # Calculate key drug-like properties
        props = {
            'SMILES': smiles,
            'Score': row['Score'],
            'MW': Descriptors.MolWt(mol),
            'LogP': Crippen.MolLogP(mol),
            'HBD': Descriptors.NumHDonors(mol),
            'HBA': Descriptors.NumHAcceptors(mol),
            'TPSA': Descriptors.TPSA(mol),
            'RotBonds': Descriptors.NumRotatableBonds(mol),
            'Rings': rdMolDescriptors.CalcNumRings(mol),
            'Aromatic_Rings': rdMolDescriptors.CalcNumAromaticRings(mol),
            'QED': QED.qed(mol),
            'Atoms': mol.GetNumAtoms(),
            'Lipinski_Violations': sum([
                Descriptors.MolWt(mol) > 500,
                Crippen.MolLogP(mol) > 5,
                Descriptors.NumHDonors(mol) > 5,
                Descriptors.NumHAcceptors(mol) > 10
            ])
        }
        properties.append(props)

    props_df = pd.DataFrame(properties)
    print(f" {valid_mols}/{len(df)} molecules are valid")

    # === DRUG-LIKENESS ANALYSIS ===
    print("\n=== DRUG-LIKENESS ANALYSIS ===")

    # Lipinski's Rule of Five
    lipinski_pass = props_df['Lipinski_Violations'] == 0
    print(f" Lipinski Rule of Five: {lipinski_pass.sum()}/{len(props_df)} molecules pass ({lipinski_pass.mean()*100:.1f}%)")

    # Key statistics
    print(f"\n Molecular Properties (Mean ¬± Std):")
    key_props = ['MW', 'LogP', 'HBD', 'HBA', 'TPSA', 'QED']
    for prop in key_props:
        mean_val = props_df[prop].mean()
        std_val = props_df[prop].std()
        print(f"  {prop:12s}: {mean_val:6.2f} ¬± {std_val:5.2f}")

    # === NOVELTY ANALYSIS ===
    print(f"\n=== MOLECULAR DIVERSITY ===")
    print(f" Unique molecules: {len(props_df)} (100% - good!)")
    print(f" Score distribution:")
    print(f"  Top 10%:  Score > {props_df['Score'].quantile(0.9):.3f}")
    print(f"  Top 25%:  Score > {props_df['Score'].quantile(0.75):.3f}")
    print(f"  Median:   Score = {props_df['Score'].median():.3f}")

    # === TOP MOLECULES ===
    print(f"\n=== TOP 10 MOLECULES ===")
    top10 = props_df.nlargest(10, 'Score')[['SMILES', 'Score', 'MW', 'LogP', 'QED', 'Lipinski_Violations']]
    print(top10.to_string(index=False))

    # === VISUALIZATION ===
    create_analysis_plots(props_df)

    # Save detailed analysis
    props_df.to_csv("detailed_molecule_analysis.csv", index=False)
    print(f"\n Detailed analysis saved to detailed_molecule_analysis.csv")

    return props_df

def create_analysis_plots(props_df):
    """Create visualization plots for molecule analysis."""

    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    fig.suptitle('PPO-Generated Molecules Analysis', fontsize=16, fontweight='bold')

    # 1. Score distribution
    axes[0,0].hist(props_df['Score'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')
    axes[0,0].set_xlabel('Hybrid Model Score')
    axes[0,0].set_ylabel('Count')
    axes[0,0].set_title('Score Distribution')
    axes[0,0].grid(True, alpha=0.3)

    # 2. Molecular Weight vs LogP (Lipinski space)
    scatter = axes[0,1].scatter(props_df['MW'], props_df['LogP'],
                               c=props_df['Score'], cmap='viridis', alpha=0.7)
    axes[0,1].axvline(500, color='red', linestyle='--', alpha=0.7, label='MW=500')
    axes[0,1].axhline(5, color='red', linestyle='--', alpha=0.7, label='LogP=5')
    axes[0,1].set_xlabel('Molecular Weight')
    axes[0,1].set_ylabel('LogP')
    axes[0,1].set_title('Lipinski Space')
    axes[0,1].legend()
    plt.colorbar(scatter, ax=axes[0,1], label='Score')

    # 3. QED vs Score correlation
    axes[0,2].scatter(props_df['QED'], props_df['Score'], alpha=0.6)
    axes[0,2].set_xlabel('QED (Drug-likeness)')
    axes[0,2].set_ylabel('Hybrid Model Score')
    axes[0,2].set_title('QED vs Model Score')

    # Calculate correlation
    corr = props_df['QED'].corr(props_df['Score'])
    axes[0,2].text(0.05, 0.95, f'Correlation: {corr:.3f}',
                   transform=axes[0,2].transAxes, fontweight='bold')

    # 4. Lipinski violations
    viol_counts = props_df['Lipinski_Violations'].value_counts().sort_index()
    axes[1,0].bar(viol_counts.index, viol_counts.values, alpha=0.7, color='lightcoral')
    axes[1,0].set_xlabel('Number of Lipinski Violations')
    axes[1,0].set_ylabel('Count')
    axes[1,0].set_title('Lipinski Rule Compliance')

    # 5. Key properties radar-like comparison
    key_props = ['MW', 'LogP', 'HBD', 'HBA', 'TPSA']
    means = [props_df[prop].mean() for prop in key_props]
    axes[1,1].bar(range(len(key_props)), means, alpha=0.7)
    axes[1,1].set_xticks(range(len(key_props)))
    axes[1,1].set_xticklabels(key_props, rotation=45)
    axes[1,1].set_title('Average Molecular Properties')

    # 6. Score vs complexity (number of atoms)
    axes[1,2].scatter(props_df['Atoms'], props_df['Score'], alpha=0.6, color='orange')
    axes[1,2].set_xlabel('Number of Atoms')
    axes[1,2].set_ylabel('Hybrid Model Score')
    axes[1,2].set_title('Molecular Size vs Score')

    plt.tight_layout()
    plt.savefig('molecule_analysis_plots.png', dpi=300, bbox_inches='tight')
    plt.show()

    print(" Analysis plots saved as 'molecule_analysis_plots.png'")

if __name__ == "__main__":
    # Run the analysis
    try:
        props_df = analyze_molecules()
        print(f"\n Analysis complete! Generated {len(props_df)} drug-like molecules for DprE1 inhibition.")
    except FileNotFoundError:
        print(" File 'ppo_generated_molecules_hybrid.csv' not found. Please run the PPO training first.")
    except Exception as e:
        print(f" Error during analysis: {e}")

# visualize_top_molecules.py
"""
Visualize the top-scoring PPO-generated molecules.
"""
import pandas as pd
import numpy as np
from rdkit import Chem
from rdkit.Chem import Draw, Descriptors, QED, Crippen
from rdkit.Chem.Draw import rdMolDraw2D
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle
import io
from PIL import Image

def visualize_top_molecules(csv_path="detailed_molecule_analysis.csv", n_top=12):
    """Visualize the top N molecules with their properties."""

    # Load the analysis results
    df = pd.read_csv(csv_path)
    print(f" Loading analysis for {len(df)} molecules...")

    # Get top molecules
    top_molecules = df.nlargest(n_top, 'Score')
    print(f" Visualizing top {len(top_molecules)} molecules...")

    # Create figure
    fig, axes = plt.subplots(3, 4, figsize=(20, 15))
    fig.suptitle('Top 12 PPO-Generated DprE1 Inhibitor Candidates', fontsize=16, fontweight='bold')
    axes = axes.flatten()

    for idx, (_, row) in enumerate(top_molecules.iterrows()):
        if idx >= n_top:
            break

        ax = axes[idx]

        # Generate molecule image
        mol = Chem.MolFromSmiles(row['SMILES'])
        if mol is None:
            ax.text(0.5, 0.5, 'Invalid\nSMILES', ha='center', va='center', fontsize=12)
            ax.set_title(f'Rank {idx+1}: Invalid')
            continue

        # Draw molecule
        img = Draw.MolToImage(mol, size=(400, 300))
        ax.imshow(img)
        ax.axis('off')

        # Add molecule information
        title = f'Rank {idx+1} | Score: {row["Score"]:.3f}'
        ax.set_title(title, fontsize=12, fontweight='bold')

        # Add properties as text
        props_text = f'MW: {row["MW"]:.1f}\n'
        props_text += f'LogP: {row["LogP"]:.2f}\n'
        props_text += f'QED: {row["QED"]:.3f}\n'
        props_text += f'HBD/HBA: {row["HBD"]:.0f}/{row["HBA"]:.0f}\n'
        props_text += f'Lipinski: {"‚úì" if row["Lipinski_Violations"] == 0 else "‚úó"}'

        # Color code based on Lipinski compliance
        bbox_color = 'lightgreen' if row['Lipinski_Violations'] == 0 else 'lightcoral'

        ax.text(0.02, 0.98, props_text, transform=ax.transAxes,
                verticalalignment='top', fontsize=9,
                bbox=dict(boxstyle="round,pad=0.3", facecolor=bbox_color, alpha=0.7))

    plt.tight_layout()
    plt.savefig('top_molecules_visualization.png', dpi=300, bbox_inches='tight')
    plt.show()

    # Print detailed information about top 5
    print("\n=== TOP 5 MOLECULES DETAILED INFO ===")
    for idx, (_, row) in enumerate(top_molecules.head(5).iterrows()):
        print(f"\n RANK {idx+1}: Score = {row['Score']:.3f}")
        print(f"   SMILES: {row['SMILES']}")
        print(f"   Molecular Weight: {row['MW']:.2f} Da")
        print(f"   LogP: {row['LogP']:.2f}")
        print(f"   QED (Drug-likeness): {row['QED']:.3f}")
        print(f"   H-bond Donors/Acceptors: {row['HBD']:.0f}/{row['HBA']:.0f}")
        print(f"   TPSA: {row['TPSA']:.2f} ≈≤")
        print(f"   Rotatable Bonds: {row['RotBonds']:.0f}")
        print(f"   Lipinski Violations: {row['Lipinski_Violations']:.0f}")
        print(f"   Drug-like: {' YES' if row['Lipinski_Violations'] == 0 else ' NO'}")

def create_single_molecule_detail(smiles, score, rank=1, save_name=None):
    """Create a detailed view of a single molecule."""

    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        print(" Invalid SMILES")
        return

    # Calculate all properties
    props = {
        'MW': Descriptors.MolWt(mol),
        'LogP': Crippen.MolLogP(mol),
        'HBD': Descriptors.NumHDonors(mol),
        'HBA': Descriptors.NumHAcceptors(mol),
        'TPSA': Descriptors.TPSA(mol),
        'RotBonds': Descriptors.NumRotatableBonds(mol),
        'QED': QED.qed(mol),
        'Atoms': mol.GetNumAtoms()
    }

    # Create figure with molecule and properties
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))

    # Left: Molecule structure
    img = Draw.MolToImage(mol, size=(600, 600))
    ax1.imshow(img)
    ax1.axis('off')
    ax1.set_title(f'Rank {rank} Molecule (Score: {score:.3f})', fontsize=16, fontweight='bold')

    # Right: Properties table
    ax2.axis('off')

    # Create properties table
    properties_data = [
        ['Property', 'Value', 'Ideal Range', 'Status'],
        ['Molecular Weight', f'{props["MW"]:.1f} Da', '‚â§ 500 Da', '‚úÖ' if props['MW'] <= 500 else '‚ùå'],
        ['LogP', f'{props["LogP"]:.2f}', '‚â§ 5', '‚úÖ' if props['LogP'] <= 5 else '‚ùå'],
        ['H-bond Donors', f'{props["HBD"]:.0f}', '‚â§ 5', '‚úÖ' if props['HBD'] <= 5 else '‚ùå'],
        ['H-bond Acceptors', f'{props["HBA"]:.0f}', '‚â§ 10', '‚úÖ' if props['HBA'] <= 10 else '‚ùå'],
        ['TPSA', f'{props["TPSA"]:.1f} ≈≤', '‚â§ 140 ≈≤', '‚úÖ' if props['TPSA'] <= 140 else '‚ùå'],
        ['Rotatable Bonds', f'{props["RotBonds"]:.0f}', '‚â§ 10', '‚úÖ' if props['RotBonds'] <= 10 else '‚ùå'],
        ['QED Score', f'{props["QED"]:.3f}', '> 0.5', '‚úÖ' if props['QED'] > 0.5 else '‚ùå'],
        ['Model Score', f'{score:.3f}', 'Higher better', 'üéØ'],
    ]

    # Draw table
    table = ax2.table(cellText=properties_data[1:],
                     colLabels=properties_data[0],
                     cellLoc='left',
                     loc='center',
                     colWidths=[0.4, 0.2, 0.25, 0.15])

    table.auto_set_font_size(False)
    table.set_fontsize(12)
    table.scale(1, 2)

    # Color code the table
    for i in range(1, len(properties_data)):
        if '‚úÖ' in properties_data[i][3]:
            table[(i, 3)].set_facecolor('lightgreen')
        elif '‚ùå' in properties_data[i][3]:
            table[(i, 3)].set_facecolor('lightcoral')
        elif 'üéØ' in properties_data[i][3]:
            table[(i, 3)].set_facecolor('lightblue')

    # Add SMILES string
    ax2.text(0.5, 0.15, f'SMILES: {smiles}',
             transform=ax2.transAxes, ha='center', va='center',
             fontsize=10, style='italic',
             bbox=dict(boxstyle="round,pad=0.5", facecolor='lightyellow'))

    ax2.set_title('Molecular Properties Analysis', fontsize=14, fontweight='bold')

    plt.tight_layout()
    if save_name:
        plt.savefig(f'{save_name}.png', dpi=300, bbox_inches='tight')
    plt.show()

    return props

def analyze_scaffold_diversity(df, n_top=20):
    """Analyze scaffold diversity in top molecules."""
    from rdkit.Chem.Scaffolds import MurckoScaffold

    top_molecules = df.nlargest(n_top, 'Score')
    scaffolds = {}

    print(f"\n=== SCAFFOLD DIVERSITY ANALYSIS (Top {n_top}) ===")

    for _, row in top_molecules.iterrows():
        mol = Chem.MolFromSmiles(row['SMILES'])
        if mol:
            try:
                scaffold = MurckoScaffold.GetScaffoldForMol(mol)
                scaffold_smiles = Chem.MolToSmiles(scaffold)
                if scaffold_smiles not in scaffolds:
                    scaffolds[scaffold_smiles] = []
                scaffolds[scaffold_smiles].append((row['SMILES'], row['Score']))
            except:
                continue

    print(f" Found {len(scaffolds)} unique scaffolds in top {n_top} molecules")
    print(f" Diversity ratio: {len(scaffolds)/n_top:.2f}")

    # Show most common scaffolds
    scaffold_counts = {k: len(v) for k, v in scaffolds.items()}
    sorted_scaffolds = sorted(scaffold_counts.items(), key=lambda x: x[1], reverse=True)

    print(f"\n  Most Common Scaffolds:")
    for i, (scaffold, count) in enumerate(sorted_scaffolds[:5]):
        print(f"  {i+1}. {scaffold} ({count} molecules)")

if __name__ == "__main__":
    try:
        # Main visualization
        visualize_top_molecules()

        # Load data for detailed analysis
        df = pd.read_csv("detailed_molecule_analysis.csv")

        # Show detailed view of the top molecule
        top_molecule = df.nlargest(1, 'Score').iloc[0]
        print(f"\n CHAMPION MOLECULE ANALYSIS:")
        create_single_molecule_detail(
            top_molecule['SMILES'],
            top_molecule['Score'],
            rank=1,
            save_name="champion_molecule"
        )

        # Scaffold diversity analysis
        analyze_scaffold_diversity(df)

        print("\n Visualization complete!")
        print(" Files created:")
        print("  - top_molecules_visualization.png")
        print("  - champion_molecule.png")

    except FileNotFoundError:
        print("‚ùå Please run the molecule analysis script first to generate 'detailed_molecule_analysis.csv'")
    except Exception as e:
        print(f"‚ùå Error: {e}")